{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 0\n",
        "(**7 points total**)\n",
        "\n",
        "The goal of this section is to familiarize yourself with the Python [TensorFlow API](https://www.tensorflow.org/api_docs/python/index.html).\n",
        "\n",
        "This part of the assignment is (very) similar to the first week's [TensorFlow notebook](https://github.com/datasci-w266/main/blob/master/week1/TensorFlow%20Tutorial.ipynb).  James went through it in detail in a [recorded](http://learn.datascience.berkeley.edu/local/adobecp/launch.php?cpurl=p3g4ab3qg61&recording=y&livesessionid=15968) office hour.  You may want to review those before continuing.  If you understood all that, this part should go very quickly.\n",
        "\n",
        "Before we do anything, let's import all the code we're going to need for this part of the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import graph\n",
        "import graph_test\n",
        "from matplotlib import pyplot as plt\n",
        "import unittest\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "reload(graph)\n",
        "reload(graph_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Adder (2 points)\n",
        "\n",
        "Open graph.py.  This file contains a number of skeleton classes that we will implement through the course of this notebook.\n",
        "\n",
        "Implement the methods of the AddTwo class.  In particular:\n",
        "- `__init__` should construct a graph with two placeholders (the numbers to add)\n",
        "- `Add` should execute the graph with its two arguments and return the result.  It should not reconstruct the graph each time.\n",
        "\n",
        "When you are done, execute the next cell to test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph)\n",
        "reload(graph_test)\n",
        "unittest.TextTestRunner(verbosity=2).run(\n",
        "    unittest.TestLoader().loadTestsFromName(\n",
        "        'TestAdder.test_adder', graph_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you didn't already, make sure that your adder can handle parameters of any dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph)\n",
        "reload(graph_test)\n",
        "unittest.TextTestRunner(verbosity=2).run(\n",
        "    unittest.TestLoader().loadTestsFromName(\n",
        "        'TestAdder.test_vector_adder', graph_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Affine & Fully Connected Layers\n",
        "\n",
        "In this section, you don't need to create the graph and session (but we wanted you to do it once so that you know how!).  Instead, you will simply implement functions that construct parts of a larger graph.\n",
        "\n",
        "You will first build an affine layer: $z = xW + b$ and then a stack of fully connected layers $h = f(xW + b)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Affine (1 point)\n",
        "In particular, your function will accept a TensorFlow Op that represents the value of $x$ and should return value $z$ of desired dimension.  You must construct whatever variables you need.\n",
        "\n",
        "Implement affine_layer(...).\n",
        "\n",
        "Hints:\n",
        "- use `tf.get_variable()` to create variables.\n",
        "- `W` should be randomly initialized: xavier_initialization\n",
        "- `b` should be initialized to a vector of 0s\n",
        "- `a * b` is a element-wise product.  Look for the function that performs matrix products!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph)\n",
        "reload(graph_test)\n",
        "unittest.TextTestRunner(verbosity=2).run(\n",
        "    unittest.TestLoader().loadTestsFromName(\n",
        "        'TestLayer.test_affine', graph_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FC Layers (1 point)\n",
        "Next, we'll build a fully-connected layer, which we can use to build a network of arbitrary depth.\n",
        "\n",
        "- Implement the `fully_connected_layers()` function.\n",
        "\n",
        "*Hint:* Reuse the `affine_layer()` function you already wrote!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph)\n",
        "reload(graph_test)\n",
        "unittest.TextTestRunner(verbosity=2).run(\n",
        "    unittest.TestLoader().loadTestsFromName(\n",
        "        'TestLayer.test_fully_connected_layers', graph_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training a Neural Network (3 points)\n",
        "\n",
        "Let's put it all together, and build a simple neural network that fits some training data.\n",
        "\n",
        "- Implement the `train_nn()` function.\n",
        "\n",
        "**Note:** you will need to do all the work (creating the graph and the session and a training op).\n",
        "\n",
        "To get the tests to pass, please use tf.train.GradientDescentOptimizer as your optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph_test)\n",
        "X_train, y_train, X_test, y_test = graph_test.generate_data(1000, 10)\n",
        "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap='bwr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "reload(graph)\n",
        "reload(graph_test)\n",
        "unittest.TextTestRunner(verbosity=2).run(\n",
        "    unittest.TestLoader().loadTestsFromName(\n",
        "        'TestNN.test_train_nn', graph_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That was fairly straightforward...  the data is clearly linearly separable.\n",
        "\n",
        "### Tuning Parameters\n",
        "\n",
        "Let's try something a bit harder!\n",
        "\n",
        "Here, we'll train a neural network with a couple of hidden layers before the final sigmoid.  This lets the network learn non-linear decision boundaries.\n",
        "\n",
        "Try playing around with the hyperparameters to get a feel for what happens if you set the learning rate too big (or too small), or if you don't give the network enough capacity (i.e. hidden layers and width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reload(graph_test)\n",
        "X_train, y_train, X_test, y_test = graph_test.generate_non_linear_data(1000, 10)\n",
        "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap='bwr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hidden_layers = [10, 10]\n",
        "batch_size = 50\n",
        "epochs = 2000\n",
        "learning_rate = 0.001\n",
        "predictions = graph.train_nn(X_train, y_train, X_test, hidden_layers, batch_size, epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_test[:,0], X_test[:,1], c=predictions, cmap='bwr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That looks pretty good!\n",
        "\n",
        "Let's compare the predictions vs. the labels and see what we got wrong..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.scatter(X_test[:,0], X_test[:,1], c=(predictions==y_test), cmap='bwr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only a tiny number of errors (hopefully!).  Good work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Congratulations\n",
        "\n",
        "You have implemented a deep neural network using tensorflow!\n",
        "\n",
        "One remaining API you may want to take a look at is [tf.nn.embedding_lookup](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#embedding_lookup).  As you might expect from the name, it is what to use to map word ids to word vectors.  Concretely, the first parameter is the embedding matrix (a variable of dimension vocab x wordvec length) and the second are indexes to lookup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
